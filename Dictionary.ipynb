{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Dictionary.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XdSyX7LEnCa3"
      },
      "source": [
        "The second major Python data structure is the dictionary. As you probably recall, dictionaries differ from lists in that you can access items in a dictionary by a key rather than a position. Later in this book you will see that there are many ways to implement a dictionary. The thing that is most important to notice right now is that the get item and set item operations on a dictionary are O(1). Another important dictionary operation is the contains operation. Checking to see whether a key is in the dictionary or not is also O(1)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PV5CWu5BnV69"
      },
      "source": [
        "For our last performance experiment we will compare the performance of the contains operation between lists and dictionaries. In the process we will confirm that the contains operator for lists is O(n) and the contains operator for dictionaries is O(1). \n",
        "\n",
        "The experiment we will use to compare the two is simple. Weâ€™ll make a list with a range of numbers in it. Then we will pick numbers at random and check to see if the numbers are in the list. If our performance tables are correct the bigger the list the longer it should take to determine if any one number is contained in the list.\n",
        "\n",
        "We will repeat the same experiment for a dictionary that contains numbers as the keys. In this experiment we should see that determining whether or not a number is in the dictionary is not only much faster, but the time it takes to check should remain constant even as the dictionary grows larger."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s6rTSf-moYiC"
      },
      "source": [
        "## Contains"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z-T-wgmQofQi"
      },
      "source": [
        "import timeit\n",
        "import random"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0ZqeUJldo4D3",
        "outputId": "b6743981-6888-44b2-b2eb-141fa732eeb6"
      },
      "source": [
        "print(\"Size\\tList Time\\t Dictionary Time\")\n",
        "for i in range(10000,1000001,20000):\n",
        "    t = timeit.Timer(\"random.randrange(%d) in x\"%i,\n",
        "                     \"from __main__ import random,x\")\n",
        "    x = list(range(i))\n",
        "    lst_time = t.timeit(number=1000)\n",
        "    x = {j:None for j in range(i)}\n",
        "    d_time = t.timeit(number=1000)\n",
        "    print(\"%d,%10.3f,%10.3f\" % (i, lst_time, d_time))"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Size\tList Time\t Dictionary Time\n",
            "10000,     0.082,     0.001\n",
            "30000,     0.241,     0.001\n",
            "50000,     0.396,     0.001\n",
            "70000,     0.555,     0.001\n",
            "90000,     0.707,     0.001\n",
            "110000,     0.891,     0.001\n",
            "130000,     1.068,     0.001\n",
            "150000,     1.184,     0.001\n",
            "170000,     1.360,     0.001\n",
            "190000,     1.577,     0.001\n",
            "210000,     1.746,     0.001\n",
            "230000,     1.874,     0.002\n",
            "250000,     2.089,     0.001\n",
            "270000,     2.217,     0.002\n",
            "290000,     2.432,     0.002\n",
            "310000,     2.509,     0.001\n",
            "330000,     2.689,     0.002\n",
            "350000,     2.941,     0.001\n",
            "370000,     2.925,     0.001\n",
            "390000,     3.276,     0.001\n",
            "410000,     3.297,     0.001\n",
            "430000,     3.630,     0.001\n",
            "450000,     3.732,     0.001\n",
            "470000,     3.794,     0.001\n",
            "490000,     4.062,     0.001\n",
            "510000,     4.160,     0.001\n",
            "530000,     4.365,     0.001\n",
            "550000,     4.223,     0.002\n",
            "570000,     4.645,     0.002\n",
            "590000,     4.829,     0.002\n",
            "610000,     4.875,     0.001\n",
            "630000,     5.099,     0.001\n",
            "650000,     5.252,     0.002\n",
            "670000,     5.249,     0.001\n",
            "690000,     5.652,     0.001\n",
            "710000,     5.844,     0.002\n",
            "730000,     5.776,     0.002\n",
            "750000,     6.090,     0.001\n",
            "770000,     6.075,     0.001\n",
            "790000,     6.249,     0.002\n",
            "810000,     6.385,     0.001\n",
            "830000,     6.602,     0.001\n",
            "850000,     6.808,     0.001\n",
            "870000,     7.184,     0.002\n",
            "890000,     7.098,     0.001\n",
            "910000,     7.149,     0.002\n",
            "930000,     7.403,     0.001\n",
            "950000,     7.607,     0.001\n",
            "970000,     8.007,     0.002\n",
            "990000,     7.930,     0.001\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6D00g6e8o6w4"
      },
      "source": [
        "Figure 4 summarizes the results of running Listing 6. You can see that the dictionary is consistently faster. For the smallest list size of 10,000 elements a dictionary is 89.4 times faster than a list. For the largest list size of 990,000 elements the dictionary is 11,603 times faster! You can also see that the time it takes for the contains operator on the list grows linearly with the size of the list. This verifies the assertion that the contains operator on a list is O(n). It can also be seen that the time for the contains operator on a dictionary is constant even as the dictionary size grows. In fact for a dictionary size of 10,000 the contains operation took 0.004 milliseconds and for the dictionary size of 990,000 it also took 0.004 milliseconds."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hWIfaOAPsjV-"
      },
      "source": [
        "<img src=\"https://runestone.academy/runestone/books/published/pythonds/_images/listvdict.png\">"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "--tuD5ixsn74"
      },
      "source": [
        "Since Python is an evolving language, there are always changes going on behind the scenes. The latest information on the performance of Python data structures can be found on the Python website. As of this writing the Python wiki has a nice time complexity page that can be found at the <a href=\"http://wiki.python.org/moin/TimeComplexity\">Time Complexity Wiki.</a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "77FrAVoes9C_"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}